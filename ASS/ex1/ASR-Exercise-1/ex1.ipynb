{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELEC-E5510 — Exercise 1: \n",
    "## Feature extraction and Modeling the feature distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this exercise is to get familiar with the feature extraction process used in automatic speech recognition and to learn about the models we typically use to model the feature distributions. \n",
    "\n",
    "This notebook first runs through the practical computational steps for producing MFCC features. The code blocks are runnable and you may want to create new code blocks to run your own code. See e.g. [this](https://wiki.python.org/moin/BeginnersGuide/Programmers) if you wish to learn Python, and [this](https://nbviewer.jupyter.org/github/ipython/ipython/blob/3.x/examples/Notebook/Index.ipynb) for help with Notebooks. \n",
    "\n",
    "The notebook also includes the questions to be answered in your submission. Submit your answers in a separate PDF document; don't submit the notebook itself.\n",
    "\n",
    "First we'll need to import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import lfilter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the data that we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleword = np.load('sampleword.npy')\n",
    "M = np.load('M.npy')\n",
    "D = np.load('D.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC feature extraction step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information about each step of MFCC: [Mel Frequency Cepstral Coefficient (MFCC) tutorial](http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/).\n",
    "\n",
    "Let's start the exercise by extracting the so-called MFCC features of a sample word. Variable 'sampleword' contains a waveform of a Finnish word 'pyörremyrskyistä' sampled at the rate of 16000Hz. You can plot it by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (30, 10)\n",
    "plt.plot(sampleword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of the feature extraction is the computation of the short-time Fourier spectrum. With Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function for plotting the spectrograms\n",
    "def plot_spectrogram(spec):\n",
    "    pho_times = [20, 26, 34, 43, 50, 59, 70, 77, 85, 94, 102, 109, 115, 123, 131]\n",
    "    pho_labels=['p','y','ö','rr','e','m','y','r','s','k','y','i','s','t','ä']\n",
    "    plt.xticks(pho_times, pho_labels)\n",
    "    plt.ylim(0, spec.shape[0])\n",
    "    plt.tick_params(labelsize=20)\n",
    "    plt.imshow(spec, cmap='terrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 400\n",
    "nfft=513\n",
    "noverlap = 240\n",
    "\n",
    "f, t, s = signal.spectrogram(sampleword, window=signal.hamming(window_size), noverlap=noverlap, nfft=nfft)\n",
    "s = np.sqrt(np.abs(s))\n",
    "\n",
    "plot_spectrogram(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This extracts the short-time Fourier spectrum of the sample word, using 25ms Hamming window and 10ms frame rate, and displays it.\n",
    "\n",
    "It is advisable to apply a high-pass filter to the waveform before taking the spectrum. You can compare the results with and without the filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 400\n",
    "nfft = 513\n",
    "noverlap = 240\n",
    "\n",
    "f, t, s2 = signal.spectrogram(lfilter([1, -0.97], 1, sampleword), window=signal.hamming(window_size), noverlap=noverlap, nfft=nfft)\n",
    "s2 = np.sqrt(np.abs(s2))\n",
    "\n",
    "plot_spectrogram(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue with the filtered version of the spectrum. The next phase is to apply a non-linear frequency transformation. The variable M contains a matrix that applied to the spectrum computes the so-called mel-spectrum. You can visualize the triangular filters in M:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(M.T, color='blue')\n",
    "plt.xlim(xmin=0)\n",
    "plt.ylim(ymin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the mel-transformation a logarithm is taken of the frequency bin energies to compress the energy values. Visualize the resulting logarithmic mel-spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pho_times = [20, 26, 34, 43, 50, 59, 70, 77, 85, 94, 102, 109, 115, 123, 131]\n",
    "pho_labels=['p','y','ö','rr','e','m','y','r','s','k','y','i','s','t','ä']\n",
    "plt.xticks(pho_times, pho_labels)\n",
    "plt.ylim(0, M.shape[0])\n",
    "plt.tick_params(labelsize=50)\n",
    "plt.imshow(np.log(M.dot(np.sqrt(np.abs(s2))) + 1), aspect='auto', cmap='terrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last phase is to decorrelate the features and reduce the dimension. This is done using the discrete cosine transformation (DCT). A variable D contains the required matrix, you can again visualize it as with matrix M or plotting the matrix with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(D)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final features are obtained simply by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pho_times = [20, 26, 34, 43, 50, 59, 70, 77, 85, 94, 102, 109, 115, 123, 131]\n",
    "pho_labels=['p','y','ö','rr','e','m','y','r','s','k','y','i','s','t','ä']\n",
    "plt.xticks(pho_times, pho_labels)\n",
    "plt.ylim(0, D.shape[0])\n",
    "plt.yticks(np.arange(0, 12, step=2))\n",
    "plt.tick_params(labelsize=50)\n",
    "plt.imshow(D.dot(np.log(M.dot(np.sqrt(np.abs(s2))) + 1)), aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final features are called Mel-frequency cepstral coefficients or MFCCs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "\n",
    "a. What are the properties of MFCC features that make them well suited for automatic speech recognition?\n",
    "\n",
    "b. Why wouldn't spectrogram or mel-spectrum features work so well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian mixture models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian mixture models (GMMs) are a very common feature distribution model in speech recognition. GMMs are flexible, general-purpose models. One of the big advantages of GMMs is having an effective estimation algorithm. Most often GMMs are estimated using the Expectation-Maximization (EM) algorithm. It is an iterative algorithm that, starting from an initial model, improves the model such that the likelihood of the model is guaranteed not to decrease at any iteration. The drawbacks of the algorithm are that the number of mixture components must be known beforehand and that in general only a local maximum of the likelihood is found. But in practice, using some heuristics and a good initialization, the EM algorithm works very well. Furthermore, the GMM estimation algorithm integrates very well into the hidden Markov model estimation algorithm, which is important in speech recognition, and which we will see later in the course.\n",
    "\n",
    "If you are interested, you can learn more about the EM algorithm from this Gentle Tutorial of the EM algorithm [Gentle Tutorial of the EM algorithm](https://people.ece.uw.edu/bilmes/p/pgs/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import mode, multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data for the GMMs contains a maximum of 3000 samples for each class, which are 17 most common Finnish phonemes. The samples have been taken from a database of 50 male speakers. There is no time structure in the training data samples, the samples have been taken from random positions of the phones. The class numbers of the training data are in variable `train_class` and the phoneme labels corresponding to the class numbers are in `phonemes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('train_data.npy')\n",
    "train_class = np.load('train_class.npy')\n",
    "test_data = np.load('test_data.npy')\n",
    "test_class = np.load('test_class.npy')\n",
    "\n",
    "tw1 = np.load('tw1.npy')\n",
    "tw2 = np.load('tw2.npy')\n",
    "tw3 = np.load('tw3.npy')\n",
    "\n",
    "phonemes = 'aehijklmnoprstuvy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(C, phonemes):\n",
    "    C = C / C.sum(axis=1)[:, np.newaxis]\n",
    "    labels = [p for p in phonemes]\n",
    "    df_cm = pd.DataFrame(C, index=labels, columns=labels)\n",
    "    fig = sns.heatmap(df_cm, square=True)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tick_params(labelsize=20)\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gmm(train_data, train_class, n_components):\n",
    "    K = len(np.unique(train_class))\n",
    "    mu =[]\n",
    "    sigma = []\n",
    "    weight = []\n",
    "    prior = []\n",
    "    stats = []\n",
    "    model = []\n",
    "\n",
    "    for k in range(K):\n",
    "        gmm = GaussianMixture(n_components, \n",
    "                              covariance_type='diag', \n",
    "                              max_iter=500, \n",
    "                              random_state=0)\n",
    "        \n",
    "        cvals = train_data[(train_class == k)]\n",
    "        N = cvals.shape[0]\n",
    "\n",
    "        gmm.fit(cvals)\n",
    "        \n",
    "        mu.append(gmm.means_)\n",
    "        sigma.append(gmm.covariances_)\n",
    "        weight.append(gmm.weights_)  \n",
    "        prior.append(N / train_data.shape[0])\n",
    "        model.append(gmm)\n",
    "    \n",
    "    bayesS = {'mu': np.array(mu), 'sigma': np.array(sigma), 'prior': prior, 'weight': np.array(weight), 'model': model}\n",
    "    return bayesS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "z = StandardScaler()\n",
    "train_data_normalized = z.fit_transform(train_data)\n",
    "test_data_normalized = z.transform(test_data)\n",
    "tw1_normalized = z.transform(tw1)\n",
    "tw2_normalized = z.transform(tw2)\n",
    "tw3_normalized = z.transform(tw3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `train_gmm` function, train a GMM by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 10\n",
    "S = train_gmm(train_data_normalized, train_class, n_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `n_components` is the number of mixture components for each class. The command returns a structure S that contains all the necessary information about the Gaussian mixture models. Here, the mixture components are 26-dimensional and the covariances of the mixture components have been restricted to be diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train_data, S, n_components):\n",
    "    N = train_data.shape[0]\n",
    "    K = S['sigma'].shape[0]\n",
    "    mu_ = S['mu']\n",
    "    sigma_ = S['sigma']\n",
    "    prior_ = S['prior']\n",
    "    weight_ = S['weight']\n",
    "    model_ = S['model']\n",
    "    pdf = np.zeros((N, K))\n",
    "\n",
    "    for k in range(K):\n",
    "        p = np.zeros((N, 1))\n",
    "        weight = weight_[k]\n",
    "        mu = mu_[k]\n",
    "        sigma = sigma_[k]\n",
    "        prior = prior_[k]\n",
    "        model = model_[k]\n",
    "        \n",
    "        likelihood = np.exp(model.score_samples(train_data))\n",
    "        pdf[:, k] = prior * likelihood.reshape(-1, 1).ravel()\n",
    "        \n",
    "    predictions = np.argmax(pdf, axis=1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The newly trained GMM can be used for recognition by chaining the computation of density functions and decision processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(train_data_normalized, S, n_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predictions` contains now the recognized class numbers of the training data. It is a large vector, to view a part of it decoded with the phoneme labels, type e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_predictions = predictions[2991:3010]\n",
    "predicted_phonemes = [phonemes[x] for x in subsample_predictions]\n",
    "print(''.join(predicted_phonemes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the recognition results of 10 samples of /a/ and 10 samples of /e/ phones.\n",
    "\n",
    "Lastly, you can compute the error percentage of the recognition by comparing the result to the reference class numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(predictions, train_class) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "\n",
    "Variables `test_data` and `test_class` contain the same kind of data as the training data but independent of the training data. In this case it was obtained from different speakers than the training data. Using the training data, train phoneme models with different numbers of components and evaluate their performance with both the training set and the independent test set.\n",
    "\n",
    "<b>Plot</b> the error rates of both the train and the test sets with <b>respect to the number of components in GMMs.</b>\n",
    "\n",
    "<b>Answer the following questions:</b>\n",
    "\n",
    "a. Why are the recognition results with the train and the test set different?\n",
    "\n",
    "b. What is a good number of components for recognizing an unknown set of samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "\n",
    "Using your best model, classify the test data and generate a confusion matrix using the provided function `confusion_matrix`, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = confusion_matrix(train_class, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the confusion matrix with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(C, phonemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer the following questions:</b>\n",
    "\n",
    "a. Based on the confusion matrix, what can you conclude about phoneme recognition as a task and recognition performance of different phoneme classifiers?\n",
    "\n",
    "b. Give examples of difficulties this classifier has.\n",
    "\n",
    "c. Include the (visualized) confusion matrix with the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4:\n",
    "\n",
    "Variables `tw1`, `tw2` and `tw3` contain the feature representations of three Finnish words. <b>Classify</b> their features using your best model. \n",
    "\n",
    "<b>Answer the following questions:</b>\n",
    "\n",
    "a. Try to identify the words based on the classification result. (We believe this demonstration works especially well if you <i>don't</i> speak Finnish. Points are rewarded for attempts, not correct answers.)\n",
    "\n",
    "b. What problems do you see in the frame based classification if one wants to recognize whole words?\n",
    "\n",
    "c. Describe ideas to improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative models\n",
    "\n",
    "When we classified feature vectors above, we wanted to pick the most probable phoneme <i>y</i>, given a feature vector <i>x</i>. In other words, we wanted: arg max<sub>y</sub> p(y|x). However, GMMs are a generative model: they learn p(x|y) and p(y). With the Bayes rule, these can be used to find the most probable class by:\n",
    "<br><br>\n",
    "<center>arg max<sub>y</sub> p(y|x) = arg max<sub>y</sub> p(x|y)p(y)</center>\n",
    "\n",
    "We can also construct a model for p(y|x) directly. This type of model is called a discriminative model. Say we want to classify animals as cats or dogs based their silhouettes.\n",
    "\n",
    "The generative approach is to learn to draw dog silhouettes and cat silhouettes. Look at dogs, make notes about prominent features: four legs, a tail. Look at cats: four legs, a tail. To classify new silhouettes, estimate if you'd be more likely to draw something similar when drawing a cat or a dog.\n",
    "\n",
    "The discriminative approach is to just look at a bunch of dog and cat pairs and figure out what the differences are. Big whiskers: it's a cat. Large animal: it's a dog. But ask the discriminative model how many legs a dog should have? No idea.\n",
    "\n",
    "Whether the generative approach or the discriminative approach works better depends on the task. Empirically, in most speech recognition tasks the discriminative approach gives better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('images/silhouettes.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep neural networks\n",
    "\n",
    "There are many discriminative classifiers, like logistic regression or support vector machines. But Deep neural networks (DNN) classifiers have worked especially well. Since the beginning of the 2010-decade, most machine learning fields, like image classification and speech recognition, attain their state-of-the-art results by applying some type of DNN methods. Nowadays almost all speech recognition systems replace GMMs by DNNs (though GMMs are still used during the iterative process through which the most complex systems are built).\n",
    "\n",
    "Although this course does not have time to go into the details of DNNs, it would seem strange not to mention them either, since they are now used everywhere. Aalto has a popular course, where you can learn more: [CS-E4890 Deep Learning](https://oodi.aalto.fi/a/opintjakstied.jsp?OpinKohd=1129662615).  For a clear introduction, see [this video series](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi).\n",
    "\n",
    "A generative approach actually assumes a model of how the data is generated. Discriminatively trained DNNs learn distinguishing factors directly from the data. In fact they are especially good at this. Many aspects of MFCCs have been manually engineered to work with GMMs' assumptions; with DNNs some of the feature extraction steps can be skipped, and the classifier learns more powerful representations in a data-driven way.\n",
    "\n",
    "Now we will try a Multi Layer Perceptron (MLP, a basic type of DNN) classifier for our phoneme recognition task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_layers = 3\n",
    "layer_size = 256\n",
    "num_classes = len(np.unique(train_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = MLPClassifier(hidden_layer_sizes=(layer_size, layer_size),\n",
    "                    activation='relu',\n",
    "                    solver='adam',\n",
    "                    learning_rate_init=0.001,\n",
    "                    alpha=1e-4,\n",
    "                    max_iter=15,\n",
    "                    random_state=0)\n",
    "\n",
    "neural_network.fit(train_data_normalized, train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = neural_network.predict(test_data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(predictions, test_class) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_parameters = (26 * layer_size + layer_size * layer_size + layer_size * layer_size + layer_size * num_classes) + num_hidden_layers * layer_size + num_classes\n",
    "print('The total number of parameters in the MLP model is: {0}'.format(total_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = confusion_matrix(test_class, predictions)\n",
    "plot_confusion(C, phonemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5:\n",
    "\n",
    "DNNs can leverage large datasets, but here we have quite a small training set.\n",
    "\n",
    "a. Which model performs classification better, the DNN or your best GMM?\n",
    "\n",
    "b. The number of trained parameters in the DNN is reported above. Now look inside your best GMM model, the dictionary returned by `train_gmm`. Note: strictly speaking, there is a separate GMM for each class (phoneme), so count the total number of parameters for all the classes altogether. How many trained (estimated) parameters does your best GMM have (Remember: we used diagonal-covariance matrix GMMs)? Which model type used more parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "\n",
    "Since the GMM is a generative model, we can sample some MFCCs from it. Sample 100 MFCCs from each phoneme class by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(gmm_models, sampled_class):\n",
    "    sampled_data = []\n",
    "    for cls in sampled_class:\n",
    "        gmm_model = gmm_models[cls]\n",
    "        sampled_data.append(gmm_model.sample(1)[0])\n",
    "    return np.array(sampled_data).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_class = np.arange(0, 17, 1).repeat(100)\n",
    "gmm_models = S['model']\n",
    "sampled_data = sample(gmm_models, sampled_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that sampled_class has the reference `class numbers`.\n",
    "\n",
    "Now classify the sampled MFCCs with the GMM model, just like you did with `train_data` and `test_data`. Then classify them with the DNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMM predict\n",
    "predictions = predict(sampled_data, S, n_components)\n",
    "print(accuracy_score(predictions, sampled_class) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN predict\n",
    "sampled_data_normalized = z.transform(sampled_data)\n",
    "predictions = neural_network.predict(sampled_data_normalized)\n",
    "print(accuracy_score(predictions, sampled_class) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6:\n",
    "\n",
    "a. Which model has lower classification error on the sampled MFCCs? Why might that be?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
